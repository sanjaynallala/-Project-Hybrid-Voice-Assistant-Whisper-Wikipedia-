PROJECT: Hybrid Voice Assistant (Whisper + Wikipedia)
ğŸ”µ PHASE 1 â€” Install Python Properly
âœ… Step 1: Download Python 3.10.9

Go to:

ğŸ‘‰ https://www.python.org/downloads/release/python-3109/

Download:

Windows installer (64-bit)

âœ… Step 2: Install Python

During installation:

âœ” Check Add Python to PATH
âœ” Click Customize Installation
âœ” Enable all optional features
âœ” Install for all users

Finish installation.

âœ… Step 3: Verify Installation

Open PowerShell:

py -0


You should see:

-V:3.10 Python 3.10.9


Then:

py -3.10 --version


Should show:

Python 3.10.9

ğŸ”µ PHASE 2 â€” Create Project Folder
âœ… Step 4: Create Folder

Go to Desktop.

Create folder:

speech_nlp_project

âœ… Step 5: Open PowerShell Inside Folder

Click address bar â†’ type:

powershell


Press Enter.

ğŸ”µ PHASE 3 â€” Create Virtual Environment
âœ… Step 6: Create venv
py -3.10 -m venv venv

âœ… Step 7: Activate venv
.\venv\Scripts\Activate


You should see:

(venv) PS C:\Users\Sanjay\Desktop\speech_nlp_project>

âœ… Step 8: Confirm Python Version
python --version


Must show:

Python 3.10.9

ğŸ”µ PHASE 4 â€” Install Required Libraries
âœ… Step 9: Install Dependencies
pip install openai-whisper torch sounddevice scipy pyttsx3 wikipedia


Wait until installation completes.

ğŸ”µ PHASE 5 â€” Install FFmpeg (VERY IMPORTANT)

Whisper requires FFmpeg.

âœ… Step 10: Download FFmpeg

Go to:

ğŸ‘‰ https://www.gyan.dev/ffmpeg/builds/

Download:

ffmpeg-release-essentials.zip and 72z600.exe

âœ… Step 11: Extract

Extract zip.

Rename folder to:

ffmpeg


Move it to:

C:\ffmpeg


So path becomes:

C:\ffmpeg\bin

ğŸ”µ PHASE 6 â€” Add FFmpeg to Environment Variables
âœ… Step 12: Open Environment Variables

Press Windows key

Search: Environment Variables

Click: Edit the system environment variables

Click: Environment Variables

âœ… Step 13: Edit PATH

Under:

System variables


Find:

Path


Click Edit.

Click New.

Add:

C:\ffmpeg\bin


Click OK â†’ OK â†’ OK.

âœ… Step 14: Restart PowerShell

Close all terminals.

Open new PowerShell.

Test:

ffmpeg -version


If version appears â†’ correct.

ğŸ”µ PHASE 7 â€” Create Project Files
âœ… Step 15: Create assistant.py

Inside project folder:

Create file:

assistant.py


Paste your final hybrid code.

ğŸ”µ PHASE 8 â€” How It Works Internally
ğŸ¤ Recording

Uses:

sounddevice
scipy.io.wavfile


Creates:

audio.wav

ğŸ§  Speech Recognition

Uses:

whisper.load_model("base")
model.transcribe()


This uses:

Transformer model

PyTorch backend

CPU inference

ğŸŒ Knowledge Search

Uses:

wikipedia.summary()


Requires internet.

ğŸ”Š Text-to-Speech

Uses:

pyttsx3


Offline speech synthesis.

ğŸ”µ PHASE 9 â€” Final Execution
âœ… Step 16: Run Assistant
python assistant.py


Flow:

Record â†’ Transcribe â†’ Process â†’ Search â†’ Speak

ğŸ”µ PHASE 10 â€” Troubleshooting You Faced

You solved:

âœ” Python version incompatibility
âœ” Tokenizers Rust error
âœ” Transformers version issue
âœ” OpenAI quota error
âœ” FFmpeg not recognized
âœ” Environment variable setup
âœ” PATH configuration
âœ” Microphone detection
âœ” Sample rate error
âœ” venv activation issue

Thatâ€™s real debugging experience.

ğŸ“ Final Architecture
Windows OS
   â†“
Python 3.10
   â†“
Virtual Environment
   â†“
Whisper + Torch
   â†“
Wikipedia API
   â†“
pyttsx3
   â†“
Hybrid Voice Assistant

ğŸ” Your Project Flow (Technically Correct Version)

1ï¸âƒ£ User speaks through microphone.
2ï¸âƒ£ Audio input is captured and passed to OpenAI Whisper, which converts speech into text (Speech-to-Text).
3ï¸âƒ£ The generated text is processed using basic NLP techniques to understand the user query.
4ï¸âƒ£ The processed query is sent to the Wikipedia API to fetch relevant information.
5ï¸âƒ£ The retrieved response text is converted into speech using pyttsx3 (Text-to-Speech).
6ï¸âƒ£ The assistant delivers the spoken response back to the user.
